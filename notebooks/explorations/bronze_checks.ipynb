{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b496d6",
   "metadata": {},
   "source": [
    "Practice Cell to explore and validate the Bronze data - Mini Challenges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb82cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_dir = os.path.abspath('')\n",
    "# Add parent directory to Python path to allow module imports\n",
    "sys.path.append(os.path.abspath(os.path.join(current_dir,'..','..')))\n",
    "\n",
    "from etl.common import get_spark, load_yml, project_root\n",
    "\n",
    "root = project_root()\n",
    "cfg = load_yml(str(root / \"configs\" / \"bronze_config.yml\"))\n",
    "fmt = cfg[\"storage\"][\"format\"]\n",
    "\n",
    "spark = get_spark(\"bronze-mini-challenges\")\n",
    "\n",
    "bronze_matches_path = root / cfg[\"tables\"][\"matches\"][\"target_path\"]\n",
    "bronze_deliveries_path = root / cfg[\"tables\"][\"deliveries\"][\"target_path\"]\n",
    "\n",
    "matches = spark.read.format(fmt).load(str(bronze_matches_path))\n",
    "deliveries = spark.read.format(fmt).load(str(bronze_deliveries_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72096719",
   "metadata": {},
   "source": [
    "Challenge 1 — Deliveries count vs matches\n",
    "\n",
    "Goal: compute deliveries per match and see top matches (useful to spot super overs / anomalies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ebd1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 matches by deliveries_count\n",
      "+----------------+----------------+\n",
      "|match_id        |deliveries_count|\n",
      "+----------------+----------------+\n",
      "|eef1376b596f046c|269             |\n",
      "|755403f168d4e0fe|267             |\n",
      "|af039871ce7fb9ae|265             |\n",
      "+----------------+----------------+\n",
      "\n",
      "Summary stats(deliveries per match)\n",
      "+---+------+---+------------------+\n",
      "|min|median|max|               avg|\n",
      "+---+------+---+------------------+\n",
      "| 51|   245|269|237.98545765611635|\n",
      "+---+------+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dpm = ( deliveries\n",
    "       .groupBy(\"match_id\")\n",
    "       .count()\n",
    "       .withColumnRenamed(\"count\",\"deliveries_count\")\n",
    "       )\n",
    "print(\"Top 3 matches by deliveries_count\")\n",
    "(dpm.orderBy(F.desc(\"deliveries_count\"))\n",
    " .limit(3)\n",
    " .show(truncate=False))\n",
    "print(\"Summary stats(deliveries per match)\")\n",
    "(dpm.select(F.min(\"deliveries_count\").alias(\"min\"),\n",
    "            F.expr(\"percentile_approx(deliveries_count,0.5)\").alias(\"median\"),\n",
    "            F.max(\"deliveries_count\").alias(\"max\"),\n",
    "            F.avg(\"deliveries_count\").alias(\"avg\"))\n",
    "       .show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24df3f72",
   "metadata": {},
   "source": [
    "Challenge 2 — Integrity: runs_total == runs_batter + runs_extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b1be8f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integrity violations (total != batter + extras): 0\n"
     ]
    }
   ],
   "source": [
    "violations_df = deliveries.filter(\n",
    "    F.coalesce(F.col(\"runs_total\"), F.lit(0)) !=\n",
    "    (F.coalesce(F.col(\"runs_batter\"), F.lit(0)) + F.coalesce(F.col(\"runs_extras\"), F.lit(0)))\n",
    ")\n",
    "\n",
    "violations_cnt = violations_df.count()\n",
    "print(\"Integrity violations (total != batter + extras):\", violations_cnt)\n",
    "\n",
    "# Peek a few rows if any\n",
    "if violations_cnt > 0:\n",
    "    (violations_df\n",
    "     .select(\"match_id\",\"inning_no\",\"over_no\",\"ball_in_over\",\"runs_batter\",\"runs_extras\",\"runs_total\",\"src_file_name\")\n",
    "     .orderBy(\"match_id\",\"inning_no\",\"over_no\",\"ball_in_over\")\n",
    "     .show(10, truncate=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77838aca",
   "metadata": {},
   "source": [
    "Challenge 4 — Performance tweak: output file counts\n",
    "\n",
    "Goal: tweak partitions/files and observe the number of files written per season.\n",
    "You don’t need to re-ingest everything—just write a tiny sample with different repartition values and count files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc12e357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output files with repartition(1):  1\n",
      "Output files with repartition(4):  1\n",
      "Output files with repartition(16): 1\n"
     ]
    }
   ],
   "source": [
    "# Write a small sample for one season to a temp output with different partitioning\n",
    "from datetime import datetime\n",
    "\n",
    "season_to_check = (matches.select(\"season\").orderBy(\"season\").first()[\"season\"])\n",
    "\n",
    "sample = deliveries.filter(F.col(\"season\") == season_to_check).limit(5000)\n",
    "\n",
    "def write_and_count(out_dir: Path, n_parts: int):\n",
    "    (sample.repartition(n_parts)\n",
    "           .write.mode(\"overwrite\").format(\"parquet\").save(str(out_dir)))\n",
    "    files = list((out_dir).rglob(\"part-*\"))\n",
    "    return len(files)\n",
    "\n",
    "base = root / \"data\" / \"tmp\" / f\"perf_{season_to_check}_{datetime.now().strftime('%H%M%S')}\"\n",
    "\n",
    "files_1  = write_and_count(base / \"n1\",  1)\n",
    "files_4  = write_and_count(base / \"n4\",  4)\n",
    "files_16 = write_and_count(base / \"n16\", 16)\n",
    "\n",
    "print(f\"Output files with repartition(1):  {files_1}\")\n",
    "print(f\"Output files with repartition(4):  {files_4}\")\n",
    "print(f\"Output files with repartition(16): {files_16}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
